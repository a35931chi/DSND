{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most commonly used data pipeline, which is called E T L: extract transform load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "\n",
    "An ETL pipeline is a specific kind of data pipeline and probably the most common. ETL stands for extract, transform, load. Imagine that you have a database containing web log data. Each entry contains the IP address of a user, a timestamp, and the link that the user clicked.\n",
    "\n",
    "What if your company wanted to analyze links clicked by city and by day? You would need another data set that maps IP address to a city, and you would also need to extract the day from the timestamp. With an ETL pipeline, you could run code once per day that would extract the previous day's log data, map IP address to city, aggregate link clicks by city, and then load these results into a new database. That way, a data analyst or scientist would have access to a table of log data by city and day. That is more convenient than always having to run the same complex data transformations on the raw web log data.\n",
    "\n",
    "Before cloud computing, business stored their data on large, expensive, private servers. Running queries on large data sets, like raw web log data, could be expensive both economically and in terms of time. But data analysts mights need to query a database multiple times even in the same day; hence, pre-aggregating the data with an ETL pipeline makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELT\n",
    "\n",
    "ELT (extract, load, transform) pipelines have gained traction since the advent of cloud computing. Cloud computing has lowered the cost of storing data and running queries on large, raw data sets. Many of these cloud services, like Amazon Redshift, Google BigQuery, or IBM Db2 can be queried using SQL or a SQL-like language. With these tools, the data gets extracted, then loaded directly, and finally transformed at the end of the pipeline.\n",
    "\n",
    "However, ETL pipelines, are still used even with these cloud tools. Oftentimes, it still makes sense to run ETL pipelines and store data in a more readable or intuitive format. This can help data analysts and scientist work more efficiently as well as help an organization become more data driven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a summary of what these different data types look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### csv files\n",
    "\n",
    "CSV stands for comma-separated values. These types of files separate values with a comma, and each entry is on a separate line. Oftentimes, the first entry will contain variable names. Here is an example of what csv data looks like. This is an abbreviated version of the first three lines in the World Bank projects data csv file.\n",
    "\n",
    "    id,regionname,countryname,prodline,lendinginstr\n",
    "    P162228,Other,World;World,RE,Investment Project Financing\n",
    "    P163962,Africa,Democratic Republic of the Congo;Democratic Republic of the Congo,PE,Investment Project Financing\n",
    "\n",
    "#### JSON\n",
    "\n",
    "JSON is a file format with key/value pairs. It looks like a Python dictionary. The exact same csv file represented in JSON could look like this:\n",
    "\n",
    "    [{\"id\":\"P162228\",\"regionname\":\"Other\",\"countryname\":\"World;World\",\"prodline\":\"RE\",\"lendinginstr\":\"Investment Project Financing\"},{\"id\":\"P163962\",\"regionname\":\"Africa\",\"countryname\":\"Democratic Republic of the Congo;Democratic Republic of the Congo\",\"prodline\":\"PE\",\"lendinginstr\":\"Investment Project Financing\"},{\"id\":\"P167672\",\"regionname\":\"South Asia\",\"countryname\":\"People\\'s Republic of Bangladesh;People\\'s Republic of Bangladesh\",\"prodline\":\"PE\",\"lendinginstr\":\"Investment Project Financing\"}]\n",
    "    \n",
    "Each line in the data is inside of a squiggly bracket {}. The variable names are the keys, and the variable values are the values.\n",
    "\n",
    "There are other ways to organize JSON data, but the general rule is that JSON is organized into key/value pairs. For example, here is a different way to represent the same data using JSON:\n",
    "\n",
    "    {\"id\":{\"0\":\"P162228\",\"1\":\"P163962\",\"2\":\"P167672\"},\"regionname\":{\"0\":\"Other\",\"1\":\"Africa\",\"2\":\"South Asia\"},\"countryname\":{\"0\":\"World;World\",\"1\":\"Democratic Republic of the Congo;Democratic Republic of the Congo\",\"2\":\"People\\'s Republic of Bangladesh;People\\'s Republic of Bangladesh\"},\"prodline\":{\"0\":\"RE\",\"1\":\"PE\",\"2\":\"PE\"},\"lendinginstr\":{\"0\":\"Investment Project Financing\",\"1\":\"Investment Project Financing\",\"2\":\"Investment Project Financing\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML\n",
    "\n",
    "Another data format is called XML (Extensible Markup Language). XML is very similar to HTML at least in terms of formatting. The main difference between the two is that HTML has pre-defined tags that are standardized. In XML, tags can be tailored to the data set. Here is what this same data would look like as XML.\n",
    "\n",
    "    <ENTRY>\n",
    "      <ID>P162228</ID>\n",
    "      <REGIONNAME>Other</REGIONNAME>\n",
    "      <COUNTRYNAME>World;World</COUNTRYNAME>\n",
    "      <PRODLINE>RE</PRODLINE>\n",
    "      <LENDINGINSTR>Investment Project Financing</LENDINGINSTR>\n",
    "    </ENTRY>\n",
    "    <ENTRY>\n",
    "      <ID>P163962</ID>\n",
    "      <REGIONNAME>Africa</REGIONNAME>\n",
    "      <COUNTRYNAME>Democratic Republic of the Congo;Democratic Republic of the Congo</COUNTRYNAME>\n",
    "      <PRODLINE>PE</PRODLINE>\n",
    "      <LENDINGINSTR>Investment Project Financing</LENDINGINSTR>\n",
    "    </ENTRY>\n",
    "    <ENTRY>\n",
    "      <ID>P167672</ID>\n",
    "      <REGIONNAME>South Asia</REGIONNAME>\n",
    "      <COUNTRYNAME>People's Republic of Bangladesh;People's Republic of Bangladesh</COUNTRYNAME>\n",
    "      <PRODLINE>PE</PRODLINE>\n",
    "      <LENDINGINSTR>Investment Project Financing</LENDINGINSTR>\n",
    "    </ENTRY>\n",
    "\n",
    "XML has fallen out of favor especially because JSON tends to be easier to navigate; however, you still might come across XML data. The World Bank API, for example, can return either XML data or JSON data. If you do any web-scraping, which will be covered later in the lesson, you will need to navigate HTML to extract the data. The process for handling HTML and XML data is essentially the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL databases\n",
    "\n",
    "SQL databases store data in tables using primary and foreign keys. In a SQL database, the same data would look like this:\n",
    "`\n",
    "    id \tregionname \tcountryname \tprodline \tlendinginstr\n",
    "    P162228 \tOther \tWorld;World \tRE \tInvestment Project Financing\n",
    "    P163962 \tAfrica \tDemocratic Republic of the Congo;Democratic Republic of the Congo \tPE \tInvestment Project Financing\n",
    "    P167672 \tSouth Asia \tPeople's Republic of Bangladesh;People's Republic of Bangladesh \tPE \tInvestment Project Financing\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Files\n",
    "\n",
    "This course won't go into much detail about text data. There are other Udacity courses, namely on natural language processing, that go into the details of processing text files.\n",
    "\n",
    "Here is an overview of about dealing with text in ETL pipelines.\n",
    "\n",
    "Text data present their own issues. Whereas csv, json, xml, and SQL data are organized with a clear structure, text is more ambiguous. For example, the World Bank project data country names are written like this\n",
    "\n",
    "Democratic Republic of the Congo;Democratic Republic of the Congo\n",
    "\n",
    "In the World Bank Indicator data sets, the Democratic Republic of the Congo is represented by the abbreviation \"Congo, Dem. Rep.\" You'll have to clean these country names to join the data sets together.\n",
    "\n",
    "Here is another example of text data. This is the beginning of Lewis Carroll's Alice in Wonderland.\n",
    "\n",
    "    CHAPTER I \n",
    "\n",
    "    Down the Rabbit-Hole \n",
    "\n",
    "    Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
    "\n",
    "With text data, one common task is to count the number of times a word appears. Essentially, you can tell that a new word starts whenever there is a space. But in this example, the word and appears as and as well as 'and. The word Down is capitalized in the chapter title, but the word down with no capitalization might appear later. These ambiguities makes working with text especially tricky. This lesson won't go into too much detail about manipulating text data. But you will get some practice working with text in the World Bank data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
