{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing Pipelines\n",
    "\n",
    "In this lesson, you'll be introduced to some of the steps involved in a NLP pipeline:\n",
    "\n",
    "    1. Text Processing - Take raw input text, clean it, normalize it, and convert it into a form that is suitable for feature extraction.\n",
    "       - Cleaning\n",
    "       - Normalization\n",
    "       - Tokenization\n",
    "       - Stop Word Removal\n",
    "       - Part of Speech Tagging\n",
    "       - Named Entity Recognition\n",
    "       - Stemming and Lemmatization\n",
    "    2. Feature Extraction - Extract and produce feature representations that are appropriate for the type of NLP task you are trying to accomplish and the type of model you are planning to use.\n",
    "       - Bag of Words\n",
    "       - TF-IDF\n",
    "       - Word Embeddings\n",
    "    3. Modeling - Design a statistical or machine learning model, fit its parameters to training data, use an optimization procedure, and then use it to make predictions about unseen data.\n",
    "    \n",
    "This process isn't always linear and may require additional steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udacity prescribed text processing steps:\n",
    "    1. normalize text and remove punctuation\n",
    "    2. split and tokenize\n",
    "    3. remove stopwords (reduce vocab)\n",
    "    4. lemmatize first then stem\n",
    "    \n",
    "This is my 2 cents:\n",
    "    1. use NER (named entity recognition, also GPE (geo-political entity))\n",
    "    2. normalize text and remove punctuation (possibly also numbers, url, etc)\n",
    "    3. split and tokenize\n",
    "    4. remove stopwords\n",
    "    5. lemmatize first then stem\n",
    "    6. phrase modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depends on what you want to do with NLP, use a different feature extraction technique:\n",
    "1. For spam detection or sentiment analysis, which are per doc representation: bag-of-words, doc-to-vec\n",
    "2. Working with individual word such as text generation, machine translation, use word level representation: word-to-vec or glove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words (treat each words as equally important)\n",
    "- unordered collection of words, hence \"bag\"\n",
    "- normalization, remove stop words, lemmatizing, stemming, etc\n",
    "- treat the unordered token as a set\n",
    "\n",
    "Document Term Matrix\n",
    "- more efficient to turn each doc into vector of numbers, representing each time they appear in the document\n",
    "- use dot product to compare the two documents (similarity and differences)\n",
    "- use cosine similarity\n",
    "\n",
    "#### TF-IDF (proportional to frequency in a document, but inversely proportional to the number of documents the words appears in, in an attemp to highlight uniqueness)\n",
    "- term frequency x inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look up applications for: word2vec, GloVe(Global Cectors for word representations), Embedding for, t-SNE, and embeddings for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
