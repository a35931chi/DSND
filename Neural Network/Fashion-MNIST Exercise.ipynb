{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='images/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebook though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, it's time to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (7): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Define your network architecture here\n",
    "# Hyperparameters for our network\n",
    "# Build a feed-forward network\n",
    "input_size = 784\n",
    "hidden_sizes = [400, 200, 100]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[2], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) #use stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30...  Loss: 2.3026\n",
      "Epoch: 1/30...  Loss: 2.3022\n",
      "Epoch: 1/30...  Loss: 2.3019\n",
      "Epoch: 1/30...  Loss: 2.3016\n",
      "Epoch: 1/30...  Loss: 2.3011\n",
      "Epoch: 1/30...  Loss: 2.3006\n",
      "Epoch: 1/30...  Loss: 2.3004\n",
      "Epoch: 1/30...  Loss: 2.3000\n",
      "Epoch: 1/30...  Loss: 2.2997\n",
      "Epoch: 1/30...  Loss: 2.2991\n",
      "Epoch: 1/30...  Loss: 2.2987\n",
      "Epoch: 1/30...  Loss: 2.2982\n",
      "Epoch: 1/30...  Loss: 2.2982\n",
      "Epoch: 1/30...  Loss: 2.2969\n",
      "Epoch: 1/30...  Loss: 2.2970\n",
      "Epoch: 1/30...  Loss: 2.2965\n",
      "Epoch: 1/30...  Loss: 2.2960\n",
      "Epoch: 1/30...  Loss: 2.2952\n",
      "Epoch: 1/30...  Loss: 2.2945\n",
      "Epoch: 1/30...  Loss: 2.2935\n",
      "Epoch: 1/30...  Loss: 2.2935\n",
      "Epoch: 1/30...  Loss: 2.2926\n",
      "Epoch: 1/30...  Loss: 2.2908\n",
      "Epoch: 2/30...  Loss: 1.2597\n",
      "Epoch: 2/30...  Loss: 2.2887\n",
      "Epoch: 2/30...  Loss: 2.2885\n",
      "Epoch: 2/30...  Loss: 2.2871\n",
      "Epoch: 2/30...  Loss: 2.2846\n",
      "Epoch: 2/30...  Loss: 2.2839\n",
      "Epoch: 2/30...  Loss: 2.2817\n",
      "Epoch: 2/30...  Loss: 2.2773\n",
      "Epoch: 2/30...  Loss: 2.2762\n",
      "Epoch: 2/30...  Loss: 2.2724\n",
      "Epoch: 2/30...  Loss: 2.2678\n",
      "Epoch: 2/30...  Loss: 2.2643\n",
      "Epoch: 2/30...  Loss: 2.2578\n",
      "Epoch: 2/30...  Loss: 2.2453\n",
      "Epoch: 2/30...  Loss: 2.2379\n",
      "Epoch: 2/30...  Loss: 2.2289\n",
      "Epoch: 2/30...  Loss: 2.2139\n",
      "Epoch: 2/30...  Loss: 2.2044\n",
      "Epoch: 2/30...  Loss: 2.2070\n",
      "Epoch: 2/30...  Loss: 2.1993\n",
      "Epoch: 2/30...  Loss: 2.1815\n",
      "Epoch: 2/30...  Loss: 2.1851\n",
      "Epoch: 2/30...  Loss: 2.1801\n",
      "Epoch: 3/30...  Loss: 0.2170\n",
      "Epoch: 3/30...  Loss: 2.1766\n",
      "Epoch: 3/30...  Loss: 2.1690\n",
      "Epoch: 3/30...  Loss: 2.1601\n",
      "Epoch: 3/30...  Loss: 2.1578\n",
      "Epoch: 3/30...  Loss: 2.1510\n",
      "Epoch: 3/30...  Loss: 2.1450\n",
      "Epoch: 3/30...  Loss: 2.1270\n",
      "Epoch: 3/30...  Loss: 2.1317\n",
      "Epoch: 3/30...  Loss: 2.1259\n",
      "Epoch: 3/30...  Loss: 2.1152\n",
      "Epoch: 3/30...  Loss: 2.1063\n",
      "Epoch: 3/30...  Loss: 2.0962\n",
      "Epoch: 3/30...  Loss: 2.0869\n",
      "Epoch: 3/30...  Loss: 2.0922\n",
      "Epoch: 3/30...  Loss: 2.0724\n",
      "Epoch: 3/30...  Loss: 2.0554\n",
      "Epoch: 3/30...  Loss: 2.0737\n",
      "Epoch: 3/30...  Loss: 2.0549\n",
      "Epoch: 3/30...  Loss: 2.0529\n",
      "Epoch: 3/30...  Loss: 2.0431\n",
      "Epoch: 3/30...  Loss: 2.0252\n",
      "Epoch: 3/30...  Loss: 2.0208\n",
      "Epoch: 3/30...  Loss: 2.0177\n",
      "Epoch: 4/30...  Loss: 1.3045\n",
      "Epoch: 4/30...  Loss: 2.0058\n",
      "Epoch: 4/30...  Loss: 1.9842\n",
      "Epoch: 4/30...  Loss: 1.9723\n",
      "Epoch: 4/30...  Loss: 1.9639\n",
      "Epoch: 4/30...  Loss: 1.9592\n",
      "Epoch: 4/30...  Loss: 1.9440\n",
      "Epoch: 4/30...  Loss: 1.9293\n",
      "Epoch: 4/30...  Loss: 1.9155\n",
      "Epoch: 4/30...  Loss: 1.9073\n",
      "Epoch: 4/30...  Loss: 1.9066\n",
      "Epoch: 4/30...  Loss: 1.8884\n",
      "Epoch: 4/30...  Loss: 1.8906\n",
      "Epoch: 4/30...  Loss: 1.8818\n",
      "Epoch: 4/30...  Loss: 1.8720\n",
      "Epoch: 4/30...  Loss: 1.8617\n",
      "Epoch: 4/30...  Loss: 1.8437\n",
      "Epoch: 4/30...  Loss: 1.8529\n",
      "Epoch: 4/30...  Loss: 1.8485\n",
      "Epoch: 4/30...  Loss: 1.8432\n",
      "Epoch: 4/30...  Loss: 1.8463\n",
      "Epoch: 4/30...  Loss: 1.8233\n",
      "Epoch: 4/30...  Loss: 1.8430\n",
      "Epoch: 5/30...  Loss: 0.3756\n",
      "Epoch: 5/30...  Loss: 1.8215\n",
      "Epoch: 5/30...  Loss: 1.8249\n",
      "Epoch: 5/30...  Loss: 1.8015\n",
      "Epoch: 5/30...  Loss: 1.8172\n",
      "Epoch: 5/30...  Loss: 1.8073\n",
      "Epoch: 5/30...  Loss: 1.7843\n",
      "Epoch: 5/30...  Loss: 1.8013\n",
      "Epoch: 5/30...  Loss: 1.7958\n",
      "Epoch: 5/30...  Loss: 1.8063\n",
      "Epoch: 5/30...  Loss: 1.8009\n",
      "Epoch: 5/30...  Loss: 1.7952\n",
      "Epoch: 5/30...  Loss: 1.7838\n",
      "Epoch: 5/30...  Loss: 1.7732\n",
      "Epoch: 5/30...  Loss: 1.7696\n",
      "Epoch: 5/30...  Loss: 1.7750\n",
      "Epoch: 5/30...  Loss: 1.7805\n",
      "Epoch: 5/30...  Loss: 1.7757\n",
      "Epoch: 5/30...  Loss: 1.7680\n",
      "Epoch: 5/30...  Loss: 1.7690\n",
      "Epoch: 5/30...  Loss: 1.7789\n",
      "Epoch: 5/30...  Loss: 1.7601\n",
      "Epoch: 5/30...  Loss: 1.7580\n",
      "Epoch: 5/30...  Loss: 1.7642\n",
      "Epoch: 6/30...  Loss: 1.3136\n",
      "Epoch: 6/30...  Loss: 1.7729\n",
      "Epoch: 6/30...  Loss: 1.7624\n",
      "Epoch: 6/30...  Loss: 1.7586\n",
      "Epoch: 6/30...  Loss: 1.7535\n",
      "Epoch: 6/30...  Loss: 1.7588\n",
      "Epoch: 6/30...  Loss: 1.7340\n",
      "Epoch: 6/30...  Loss: 1.7312\n",
      "Epoch: 6/30...  Loss: 1.7389\n",
      "Epoch: 6/30...  Loss: 1.7349\n",
      "Epoch: 6/30...  Loss: 1.7270\n",
      "Epoch: 6/30...  Loss: 1.7537\n",
      "Epoch: 6/30...  Loss: 1.7414\n",
      "Epoch: 6/30...  Loss: 1.7446\n",
      "Epoch: 6/30...  Loss: 1.7442\n",
      "Epoch: 6/30...  Loss: 1.7416\n",
      "Epoch: 6/30...  Loss: 1.7285\n",
      "Epoch: 6/30...  Loss: 1.7331\n",
      "Epoch: 6/30...  Loss: 1.7389\n",
      "Epoch: 6/30...  Loss: 1.7463\n",
      "Epoch: 6/30...  Loss: 1.7363\n",
      "Epoch: 6/30...  Loss: 1.7257\n",
      "Epoch: 6/30...  Loss: 1.7267\n",
      "Epoch: 7/30...  Loss: 0.5202\n",
      "Epoch: 7/30...  Loss: 1.7289\n",
      "Epoch: 7/30...  Loss: 1.7206\n",
      "Epoch: 7/30...  Loss: 1.7218\n",
      "Epoch: 7/30...  Loss: 1.7261\n",
      "Epoch: 7/30...  Loss: 1.7287\n",
      "Epoch: 7/30...  Loss: 1.7210\n",
      "Epoch: 7/30...  Loss: 1.7206\n",
      "Epoch: 7/30...  Loss: 1.7199\n",
      "Epoch: 7/30...  Loss: 1.7241\n",
      "Epoch: 7/30...  Loss: 1.7180\n",
      "Epoch: 7/30...  Loss: 1.7294\n",
      "Epoch: 7/30...  Loss: 1.7160\n",
      "Epoch: 7/30...  Loss: 1.7217\n",
      "Epoch: 7/30...  Loss: 1.7168\n",
      "Epoch: 7/30...  Loss: 1.7176\n",
      "Epoch: 7/30...  Loss: 1.7223\n",
      "Epoch: 7/30...  Loss: 1.7212\n",
      "Epoch: 7/30...  Loss: 1.7050\n",
      "Epoch: 7/30...  Loss: 1.7270\n",
      "Epoch: 7/30...  Loss: 1.7148\n",
      "Epoch: 7/30...  Loss: 1.7258\n",
      "Epoch: 7/30...  Loss: 1.7117\n",
      "Epoch: 7/30...  Loss: 1.7070\n",
      "Epoch: 8/30...  Loss: 1.4508\n",
      "Epoch: 8/30...  Loss: 1.7070\n",
      "Epoch: 8/30...  Loss: 1.7147\n",
      "Epoch: 8/30...  Loss: 1.7121\n",
      "Epoch: 8/30...  Loss: 1.7074\n",
      "Epoch: 8/30...  Loss: 1.7162\n",
      "Epoch: 8/30...  Loss: 1.7042\n",
      "Epoch: 8/30...  Loss: 1.7106\n",
      "Epoch: 8/30...  Loss: 1.6986\n",
      "Epoch: 8/30...  Loss: 1.7258\n",
      "Epoch: 8/30...  Loss: 1.7024\n",
      "Epoch: 8/30...  Loss: 1.7120\n",
      "Epoch: 8/30...  Loss: 1.7094\n",
      "Epoch: 8/30...  Loss: 1.7132\n",
      "Epoch: 8/30...  Loss: 1.7012\n",
      "Epoch: 8/30...  Loss: 1.7072\n",
      "Epoch: 8/30...  Loss: 1.6931\n",
      "Epoch: 8/30...  Loss: 1.7068\n",
      "Epoch: 8/30...  Loss: 1.7020\n",
      "Epoch: 8/30...  Loss: 1.7031\n",
      "Epoch: 8/30...  Loss: 1.7129\n",
      "Epoch: 8/30...  Loss: 1.7001\n",
      "Epoch: 8/30...  Loss: 1.7033\n",
      "Epoch: 9/30...  Loss: 0.6805\n",
      "Epoch: 9/30...  Loss: 1.6986\n",
      "Epoch: 9/30...  Loss: 1.7007\n",
      "Epoch: 9/30...  Loss: 1.6925\n",
      "Epoch: 9/30...  Loss: 1.6898\n",
      "Epoch: 9/30...  Loss: 1.6814\n",
      "Epoch: 9/30...  Loss: 1.7075\n",
      "Epoch: 9/30...  Loss: 1.7020\n",
      "Epoch: 9/30...  Loss: 1.6975\n",
      "Epoch: 9/30...  Loss: 1.6882\n",
      "Epoch: 9/30...  Loss: 1.7006\n",
      "Epoch: 9/30...  Loss: 1.7080\n",
      "Epoch: 9/30...  Loss: 1.6941\n",
      "Epoch: 9/30...  Loss: 1.7003\n",
      "Epoch: 9/30...  Loss: 1.6932\n",
      "Epoch: 9/30...  Loss: 1.6920\n",
      "Epoch: 9/30...  Loss: 1.7001\n",
      "Epoch: 9/30...  Loss: 1.6917\n",
      "Epoch: 9/30...  Loss: 1.6968\n",
      "Epoch: 9/30...  Loss: 1.7115\n",
      "Epoch: 9/30...  Loss: 1.6950\n",
      "Epoch: 9/30...  Loss: 1.6892\n",
      "Epoch: 9/30...  Loss: 1.7013\n",
      "Epoch: 9/30...  Loss: 1.6950\n",
      "Epoch: 10/30...  Loss: 1.6064\n",
      "Epoch: 10/30...  Loss: 1.6879\n",
      "Epoch: 10/30...  Loss: 1.6996\n",
      "Epoch: 10/30...  Loss: 1.6928\n",
      "Epoch: 10/30...  Loss: 1.6904\n",
      "Epoch: 10/30...  Loss: 1.6945\n",
      "Epoch: 10/30...  Loss: 1.6842\n",
      "Epoch: 10/30...  Loss: 1.6860\n",
      "Epoch: 10/30...  Loss: 1.6925\n",
      "Epoch: 10/30...  Loss: 1.6930\n",
      "Epoch: 10/30...  Loss: 1.6738\n",
      "Epoch: 10/30...  Loss: 1.6922\n",
      "Epoch: 10/30...  Loss: 1.6956\n",
      "Epoch: 10/30...  Loss: 1.7013\n",
      "Epoch: 10/30...  Loss: 1.6845\n",
      "Epoch: 10/30...  Loss: 1.6920\n",
      "Epoch: 10/30...  Loss: 1.6777\n",
      "Epoch: 10/30...  Loss: 1.6842\n",
      "Epoch: 10/30...  Loss: 1.6888\n",
      "Epoch: 10/30...  Loss: 1.6989\n",
      "Epoch: 10/30...  Loss: 1.6945\n",
      "Epoch: 10/30...  Loss: 1.6903\n",
      "Epoch: 10/30...  Loss: 1.6761\n",
      "Epoch: 11/30...  Loss: 0.8378\n",
      "Epoch: 11/30...  Loss: 1.6877\n",
      "Epoch: 11/30...  Loss: 1.6855\n",
      "Epoch: 11/30...  Loss: 1.6781\n",
      "Epoch: 11/30...  Loss: 1.6777\n",
      "Epoch: 11/30...  Loss: 1.6948\n",
      "Epoch: 11/30...  Loss: 1.6990\n",
      "Epoch: 11/30...  Loss: 1.6817\n",
      "Epoch: 11/30...  Loss: 1.6893\n",
      "Epoch: 11/30...  Loss: 1.6814\n",
      "Epoch: 11/30...  Loss: 1.6821\n",
      "Epoch: 11/30...  Loss: 1.6881\n",
      "Epoch: 11/30...  Loss: 1.6805\n",
      "Epoch: 11/30...  Loss: 1.6786\n",
      "Epoch: 11/30...  Loss: 1.6882\n",
      "Epoch: 11/30...  Loss: 1.6860\n",
      "Epoch: 11/30...  Loss: 1.6741\n",
      "Epoch: 11/30...  Loss: 1.6791\n",
      "Epoch: 11/30...  Loss: 1.6763\n",
      "Epoch: 11/30...  Loss: 1.6920\n",
      "Epoch: 11/30...  Loss: 1.6735\n",
      "Epoch: 11/30...  Loss: 1.6726\n",
      "Epoch: 11/30...  Loss: 1.6836\n",
      "Epoch: 12/30...  Loss: 0.0835\n",
      "Epoch: 12/30...  Loss: 1.6731\n",
      "Epoch: 12/30...  Loss: 1.6799\n",
      "Epoch: 12/30...  Loss: 1.6833\n",
      "Epoch: 12/30...  Loss: 1.6653\n",
      "Epoch: 12/30...  Loss: 1.6796\n",
      "Epoch: 12/30...  Loss: 1.6703\n",
      "Epoch: 12/30...  Loss: 1.6714\n",
      "Epoch: 12/30...  Loss: 1.6829\n",
      "Epoch: 12/30...  Loss: 1.6746\n",
      "Epoch: 12/30...  Loss: 1.6891\n",
      "Epoch: 12/30...  Loss: 1.6917\n",
      "Epoch: 12/30...  Loss: 1.6782\n",
      "Epoch: 12/30...  Loss: 1.6923\n",
      "Epoch: 12/30...  Loss: 1.6786\n",
      "Epoch: 12/30...  Loss: 1.6839\n",
      "Epoch: 12/30...  Loss: 1.6741\n",
      "Epoch: 12/30...  Loss: 1.6717\n",
      "Epoch: 12/30...  Loss: 1.6599\n",
      "Epoch: 12/30...  Loss: 1.6825\n",
      "Epoch: 12/30...  Loss: 1.6943\n",
      "Epoch: 12/30...  Loss: 1.6788\n",
      "Epoch: 12/30...  Loss: 1.6747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/30...  Loss: 1.6669\n",
      "Epoch: 13/30...  Loss: 1.0087\n",
      "Epoch: 13/30...  Loss: 1.6681\n",
      "Epoch: 13/30...  Loss: 1.6750\n",
      "Epoch: 13/30...  Loss: 1.6727\n",
      "Epoch: 13/30...  Loss: 1.6654\n",
      "Epoch: 13/30...  Loss: 1.6659\n",
      "Epoch: 13/30...  Loss: 1.6890\n",
      "Epoch: 13/30...  Loss: 1.6771\n",
      "Epoch: 13/30...  Loss: 1.6792\n",
      "Epoch: 13/30...  Loss: 1.6691\n",
      "Epoch: 13/30...  Loss: 1.6792\n",
      "Epoch: 13/30...  Loss: 1.6667\n",
      "Epoch: 13/30...  Loss: 1.6765\n",
      "Epoch: 13/30...  Loss: 1.6861\n",
      "Epoch: 13/30...  Loss: 1.6684\n",
      "Epoch: 13/30...  Loss: 1.6737\n",
      "Epoch: 13/30...  Loss: 1.6699\n",
      "Epoch: 13/30...  Loss: 1.6684\n",
      "Epoch: 13/30...  Loss: 1.6840\n",
      "Epoch: 13/30...  Loss: 1.6675\n",
      "Epoch: 13/30...  Loss: 1.6690\n",
      "Epoch: 13/30...  Loss: 1.6764\n",
      "Epoch: 13/30...  Loss: 1.6661\n",
      "Epoch: 14/30...  Loss: 0.2542\n",
      "Epoch: 14/30...  Loss: 1.6802\n",
      "Epoch: 14/30...  Loss: 1.6766\n",
      "Epoch: 14/30...  Loss: 1.6809\n",
      "Epoch: 14/30...  Loss: 1.6677\n",
      "Epoch: 14/30...  Loss: 1.6682\n",
      "Epoch: 14/30...  Loss: 1.6662\n",
      "Epoch: 14/30...  Loss: 1.6717\n",
      "Epoch: 14/30...  Loss: 1.6741\n",
      "Epoch: 14/30...  Loss: 1.6665\n",
      "Epoch: 14/30...  Loss: 1.6617\n",
      "Epoch: 14/30...  Loss: 1.6704\n",
      "Epoch: 14/30...  Loss: 1.6813\n",
      "Epoch: 14/30...  Loss: 1.6667\n",
      "Epoch: 14/30...  Loss: 1.6665\n",
      "Epoch: 14/30...  Loss: 1.6702\n",
      "Epoch: 14/30...  Loss: 1.6693\n",
      "Epoch: 14/30...  Loss: 1.6452\n",
      "Epoch: 14/30...  Loss: 1.6814\n",
      "Epoch: 14/30...  Loss: 1.6667\n",
      "Epoch: 14/30...  Loss: 1.6664\n",
      "Epoch: 14/30...  Loss: 1.6719\n",
      "Epoch: 14/30...  Loss: 1.6687\n",
      "Epoch: 14/30...  Loss: 1.6727\n",
      "Epoch: 15/30...  Loss: 1.1654\n",
      "Epoch: 15/30...  Loss: 1.6606\n",
      "Epoch: 15/30...  Loss: 1.6668\n",
      "Epoch: 15/30...  Loss: 1.6745\n",
      "Epoch: 15/30...  Loss: 1.6651\n",
      "Epoch: 15/30...  Loss: 1.6653\n",
      "Epoch: 15/30...  Loss: 1.6706\n",
      "Epoch: 15/30...  Loss: 1.6741\n",
      "Epoch: 15/30...  Loss: 1.6642\n",
      "Epoch: 15/30...  Loss: 1.6712\n",
      "Epoch: 15/30...  Loss: 1.6867\n",
      "Epoch: 15/30...  Loss: 1.6586\n",
      "Epoch: 15/30...  Loss: 1.6640\n",
      "Epoch: 15/30...  Loss: 1.6683\n",
      "Epoch: 15/30...  Loss: 1.6684\n",
      "Epoch: 15/30...  Loss: 1.6724\n",
      "Epoch: 15/30...  Loss: 1.6666\n",
      "Epoch: 15/30...  Loss: 1.6607\n",
      "Epoch: 15/30...  Loss: 1.6635\n",
      "Epoch: 15/30...  Loss: 1.6603\n",
      "Epoch: 15/30...  Loss: 1.6702\n",
      "Epoch: 15/30...  Loss: 1.6511\n",
      "Epoch: 15/30...  Loss: 1.6718\n",
      "Epoch: 16/30...  Loss: 0.4138\n",
      "Epoch: 16/30...  Loss: 1.6642\n",
      "Epoch: 16/30...  Loss: 1.6652\n",
      "Epoch: 16/30...  Loss: 1.6647\n",
      "Epoch: 16/30...  Loss: 1.6592\n",
      "Epoch: 16/30...  Loss: 1.6672\n",
      "Epoch: 16/30...  Loss: 1.6726\n",
      "Epoch: 16/30...  Loss: 1.6525\n",
      "Epoch: 16/30...  Loss: 1.6716\n",
      "Epoch: 16/30...  Loss: 1.6700\n",
      "Epoch: 16/30...  Loss: 1.6602\n",
      "Epoch: 16/30...  Loss: 1.6634\n",
      "Epoch: 16/30...  Loss: 1.6702\n",
      "Epoch: 16/30...  Loss: 1.6621\n",
      "Epoch: 16/30...  Loss: 1.6665\n",
      "Epoch: 16/30...  Loss: 1.6628\n",
      "Epoch: 16/30...  Loss: 1.6570\n",
      "Epoch: 16/30...  Loss: 1.6609\n",
      "Epoch: 16/30...  Loss: 1.6679\n",
      "Epoch: 16/30...  Loss: 1.6631\n",
      "Epoch: 16/30...  Loss: 1.6614\n",
      "Epoch: 16/30...  Loss: 1.6581\n",
      "Epoch: 16/30...  Loss: 1.6663\n",
      "Epoch: 16/30...  Loss: 1.6662\n",
      "Epoch: 17/30...  Loss: 1.3244\n",
      "Epoch: 17/30...  Loss: 1.6681\n",
      "Epoch: 17/30...  Loss: 1.6586\n",
      "Epoch: 17/30...  Loss: 1.6640\n",
      "Epoch: 17/30...  Loss: 1.6804\n",
      "Epoch: 17/30...  Loss: 1.6656\n",
      "Epoch: 17/30...  Loss: 1.6548\n",
      "Epoch: 17/30...  Loss: 1.6611\n",
      "Epoch: 17/30...  Loss: 1.6734\n",
      "Epoch: 17/30...  Loss: 1.6618\n",
      "Epoch: 17/30...  Loss: 1.6513\n",
      "Epoch: 17/30...  Loss: 1.6536\n",
      "Epoch: 17/30...  Loss: 1.6684\n",
      "Epoch: 17/30...  Loss: 1.6585\n",
      "Epoch: 17/30...  Loss: 1.6645\n",
      "Epoch: 17/30...  Loss: 1.6557\n",
      "Epoch: 17/30...  Loss: 1.6786\n",
      "Epoch: 17/30...  Loss: 1.6555\n",
      "Epoch: 17/30...  Loss: 1.6509\n",
      "Epoch: 17/30...  Loss: 1.6505\n",
      "Epoch: 17/30...  Loss: 1.6534\n",
      "Epoch: 17/30...  Loss: 1.6553\n",
      "Epoch: 17/30...  Loss: 1.6599\n",
      "Epoch: 18/30...  Loss: 0.5797\n",
      "Epoch: 18/30...  Loss: 1.6647\n",
      "Epoch: 18/30...  Loss: 1.6584\n",
      "Epoch: 18/30...  Loss: 1.6690\n",
      "Epoch: 18/30...  Loss: 1.6634\n",
      "Epoch: 18/30...  Loss: 1.6601\n",
      "Epoch: 18/30...  Loss: 1.6526\n",
      "Epoch: 18/30...  Loss: 1.6508\n",
      "Epoch: 18/30...  Loss: 1.6628\n",
      "Epoch: 18/30...  Loss: 1.6677\n",
      "Epoch: 18/30...  Loss: 1.6536\n",
      "Epoch: 18/30...  Loss: 1.6690\n",
      "Epoch: 18/30...  Loss: 1.6534\n",
      "Epoch: 18/30...  Loss: 1.6525\n",
      "Epoch: 18/30...  Loss: 1.6573\n",
      "Epoch: 18/30...  Loss: 1.6667\n",
      "Epoch: 18/30...  Loss: 1.6643\n",
      "Epoch: 18/30...  Loss: 1.6676\n",
      "Epoch: 18/30...  Loss: 1.6472\n",
      "Epoch: 18/30...  Loss: 1.6534\n",
      "Epoch: 18/30...  Loss: 1.6531\n",
      "Epoch: 18/30...  Loss: 1.6518\n",
      "Epoch: 18/30...  Loss: 1.6700\n",
      "Epoch: 18/30...  Loss: 1.6580\n",
      "Epoch: 19/30...  Loss: 1.4958\n",
      "Epoch: 19/30...  Loss: 1.6549\n",
      "Epoch: 19/30...  Loss: 1.6592\n",
      "Epoch: 19/30...  Loss: 1.6561\n",
      "Epoch: 19/30...  Loss: 1.6626\n",
      "Epoch: 19/30...  Loss: 1.6603\n",
      "Epoch: 19/30...  Loss: 1.6562\n",
      "Epoch: 19/30...  Loss: 1.6564\n",
      "Epoch: 19/30...  Loss: 1.6675\n",
      "Epoch: 19/30...  Loss: 1.6392\n",
      "Epoch: 19/30...  Loss: 1.6661\n",
      "Epoch: 19/30...  Loss: 1.6486\n",
      "Epoch: 19/30...  Loss: 1.6677\n",
      "Epoch: 19/30...  Loss: 1.6501\n",
      "Epoch: 19/30...  Loss: 1.6650\n",
      "Epoch: 19/30...  Loss: 1.6593\n",
      "Epoch: 19/30...  Loss: 1.6583\n",
      "Epoch: 19/30...  Loss: 1.6623\n",
      "Epoch: 19/30...  Loss: 1.6565\n",
      "Epoch: 19/30...  Loss: 1.6611\n",
      "Epoch: 19/30...  Loss: 1.6515\n",
      "Epoch: 19/30...  Loss: 1.6624\n",
      "Epoch: 19/30...  Loss: 1.6453\n",
      "Epoch: 20/30...  Loss: 0.7547\n",
      "Epoch: 20/30...  Loss: 1.6532\n",
      "Epoch: 20/30...  Loss: 1.6598\n",
      "Epoch: 20/30...  Loss: 1.6545\n",
      "Epoch: 20/30...  Loss: 1.6503\n",
      "Epoch: 20/30...  Loss: 1.6582\n",
      "Epoch: 20/30...  Loss: 1.6553\n",
      "Epoch: 20/30...  Loss: 1.6521\n",
      "Epoch: 20/30...  Loss: 1.6403\n",
      "Epoch: 20/30...  Loss: 1.6578\n",
      "Epoch: 20/30...  Loss: 1.6705\n",
      "Epoch: 20/30...  Loss: 1.6521\n",
      "Epoch: 20/30...  Loss: 1.6654\n",
      "Epoch: 20/30...  Loss: 1.6425\n",
      "Epoch: 20/30...  Loss: 1.6491\n",
      "Epoch: 20/30...  Loss: 1.6655\n",
      "Epoch: 20/30...  Loss: 1.6621\n",
      "Epoch: 20/30...  Loss: 1.6485\n",
      "Epoch: 20/30...  Loss: 1.6741\n",
      "Epoch: 20/30...  Loss: 1.6530\n",
      "Epoch: 20/30...  Loss: 1.6608\n",
      "Epoch: 20/30...  Loss: 1.6569\n",
      "Epoch: 20/30...  Loss: 1.6447\n",
      "Epoch: 20/30...  Loss: 1.6497\n",
      "Epoch: 21/30...  Loss: 1.6722\n",
      "Epoch: 21/30...  Loss: 1.6520\n",
      "Epoch: 21/30...  Loss: 1.6465\n",
      "Epoch: 21/30...  Loss: 1.6516\n",
      "Epoch: 21/30...  Loss: 1.6518\n",
      "Epoch: 21/30...  Loss: 1.6530\n",
      "Epoch: 21/30...  Loss: 1.6418\n",
      "Epoch: 21/30...  Loss: 1.6742\n",
      "Epoch: 21/30...  Loss: 1.6611\n",
      "Epoch: 21/30...  Loss: 1.6560\n",
      "Epoch: 21/30...  Loss: 1.6529\n",
      "Epoch: 21/30...  Loss: 1.6527\n",
      "Epoch: 21/30...  Loss: 1.6581\n",
      "Epoch: 21/30...  Loss: 1.6512\n",
      "Epoch: 21/30...  Loss: 1.6585\n",
      "Epoch: 21/30...  Loss: 1.6570\n",
      "Epoch: 21/30...  Loss: 1.6469\n",
      "Epoch: 21/30...  Loss: 1.6565\n",
      "Epoch: 21/30...  Loss: 1.6508\n",
      "Epoch: 21/30...  Loss: 1.6535\n",
      "Epoch: 21/30...  Loss: 1.6505\n",
      "Epoch: 21/30...  Loss: 1.6577\n",
      "Epoch: 21/30...  Loss: 1.6469\n",
      "Epoch: 22/30...  Loss: 0.9050\n",
      "Epoch: 22/30...  Loss: 1.6577\n",
      "Epoch: 22/30...  Loss: 1.6591\n",
      "Epoch: 22/30...  Loss: 1.6546\n",
      "Epoch: 22/30...  Loss: 1.6568\n",
      "Epoch: 22/30...  Loss: 1.6402\n",
      "Epoch: 22/30...  Loss: 1.6574\n",
      "Epoch: 22/30...  Loss: 1.6433\n",
      "Epoch: 22/30...  Loss: 1.6457\n",
      "Epoch: 22/30...  Loss: 1.6536\n",
      "Epoch: 22/30...  Loss: 1.6628\n",
      "Epoch: 22/30...  Loss: 1.6453\n",
      "Epoch: 22/30...  Loss: 1.6479\n",
      "Epoch: 22/30...  Loss: 1.6444\n",
      "Epoch: 22/30...  Loss: 1.6637\n",
      "Epoch: 22/30...  Loss: 1.6486\n",
      "Epoch: 22/30...  Loss: 1.6549\n",
      "Epoch: 22/30...  Loss: 1.6577\n",
      "Epoch: 22/30...  Loss: 1.6624\n",
      "Epoch: 22/30...  Loss: 1.6476\n",
      "Epoch: 22/30...  Loss: 1.6642\n",
      "Epoch: 22/30...  Loss: 1.6480\n",
      "Epoch: 22/30...  Loss: 1.6593\n",
      "Epoch: 23/30...  Loss: 0.1661\n",
      "Epoch: 23/30...  Loss: 1.6513\n",
      "Epoch: 23/30...  Loss: 1.6609\n",
      "Epoch: 23/30...  Loss: 1.6570\n",
      "Epoch: 23/30...  Loss: 1.6494\n",
      "Epoch: 23/30...  Loss: 1.6476\n",
      "Epoch: 23/30...  Loss: 1.6540\n",
      "Epoch: 23/30...  Loss: 1.6516\n",
      "Epoch: 23/30...  Loss: 1.6513\n",
      "Epoch: 23/30...  Loss: 1.6504\n",
      "Epoch: 23/30...  Loss: 1.6644\n",
      "Epoch: 23/30...  Loss: 1.6520\n",
      "Epoch: 23/30...  Loss: 1.6496\n",
      "Epoch: 23/30...  Loss: 1.6609\n",
      "Epoch: 23/30...  Loss: 1.6519\n",
      "Epoch: 23/30...  Loss: 1.6443\n",
      "Epoch: 23/30...  Loss: 1.6476\n",
      "Epoch: 23/30...  Loss: 1.6678\n",
      "Epoch: 23/30...  Loss: 1.6388\n",
      "Epoch: 23/30...  Loss: 1.6424\n",
      "Epoch: 23/30...  Loss: 1.6550\n",
      "Epoch: 23/30...  Loss: 1.6436\n",
      "Epoch: 23/30...  Loss: 1.6456\n",
      "Epoch: 23/30...  Loss: 1.6541\n",
      "Epoch: 24/30...  Loss: 1.0804\n",
      "Epoch: 24/30...  Loss: 1.6409\n",
      "Epoch: 24/30...  Loss: 1.6608\n",
      "Epoch: 24/30...  Loss: 1.6368\n",
      "Epoch: 24/30...  Loss: 1.6616\n",
      "Epoch: 24/30...  Loss: 1.6425\n",
      "Epoch: 24/30...  Loss: 1.6416\n",
      "Epoch: 24/30...  Loss: 1.6575\n",
      "Epoch: 24/30...  Loss: 1.6518\n",
      "Epoch: 24/30...  Loss: 1.6608\n",
      "Epoch: 24/30...  Loss: 1.6366\n",
      "Epoch: 24/30...  Loss: 1.6435\n",
      "Epoch: 24/30...  Loss: 1.6576\n",
      "Epoch: 24/30...  Loss: 1.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/30...  Loss: 1.6644\n",
      "Epoch: 24/30...  Loss: 1.6406\n",
      "Epoch: 24/30...  Loss: 1.6455\n",
      "Epoch: 24/30...  Loss: 1.6468\n",
      "Epoch: 24/30...  Loss: 1.6575\n",
      "Epoch: 24/30...  Loss: 1.6410\n",
      "Epoch: 24/30...  Loss: 1.6483\n",
      "Epoch: 24/30...  Loss: 1.6485\n",
      "Epoch: 24/30...  Loss: 1.6570\n",
      "Epoch: 25/30...  Loss: 0.3317\n",
      "Epoch: 25/30...  Loss: 1.6486\n",
      "Epoch: 25/30...  Loss: 1.6551\n",
      "Epoch: 25/30...  Loss: 1.6591\n",
      "Epoch: 25/30...  Loss: 1.6458\n",
      "Epoch: 25/30...  Loss: 1.6414\n",
      "Epoch: 25/30...  Loss: 1.6616\n",
      "Epoch: 25/30...  Loss: 1.6659\n",
      "Epoch: 25/30...  Loss: 1.6377\n",
      "Epoch: 25/30...  Loss: 1.6390\n",
      "Epoch: 25/30...  Loss: 1.6422\n",
      "Epoch: 25/30...  Loss: 1.6623\n",
      "Epoch: 25/30...  Loss: 1.6490\n",
      "Epoch: 25/30...  Loss: 1.6402\n",
      "Epoch: 25/30...  Loss: 1.6367\n",
      "Epoch: 25/30...  Loss: 1.6453\n",
      "Epoch: 25/30...  Loss: 1.6617\n",
      "Epoch: 25/30...  Loss: 1.6511\n",
      "Epoch: 25/30...  Loss: 1.6423\n",
      "Epoch: 25/30...  Loss: 1.6470\n",
      "Epoch: 25/30...  Loss: 1.6454\n",
      "Epoch: 25/30...  Loss: 1.6522\n",
      "Epoch: 25/30...  Loss: 1.6542\n",
      "Epoch: 25/30...  Loss: 1.6575\n",
      "Epoch: 26/30...  Loss: 1.2401\n",
      "Epoch: 26/30...  Loss: 1.6420\n",
      "Epoch: 26/30...  Loss: 1.6480\n",
      "Epoch: 26/30...  Loss: 1.6509\n",
      "Epoch: 26/30...  Loss: 1.6465\n",
      "Epoch: 26/30...  Loss: 1.6521\n",
      "Epoch: 26/30...  Loss: 1.6546\n",
      "Epoch: 26/30...  Loss: 1.6380\n",
      "Epoch: 26/30...  Loss: 1.6449\n",
      "Epoch: 26/30...  Loss: 1.6530\n",
      "Epoch: 26/30...  Loss: 1.6428\n",
      "Epoch: 26/30...  Loss: 1.6402\n",
      "Epoch: 26/30...  Loss: 1.6606\n",
      "Epoch: 26/30...  Loss: 1.6486\n",
      "Epoch: 26/30...  Loss: 1.6517\n",
      "Epoch: 26/30...  Loss: 1.6469\n",
      "Epoch: 26/30...  Loss: 1.6465\n",
      "Epoch: 26/30...  Loss: 1.6523\n",
      "Epoch: 26/30...  Loss: 1.6495\n",
      "Epoch: 26/30...  Loss: 1.6484\n",
      "Epoch: 26/30...  Loss: 1.6516\n",
      "Epoch: 26/30...  Loss: 1.6448\n",
      "Epoch: 26/30...  Loss: 1.6407\n",
      "Epoch: 27/30...  Loss: 0.4917\n",
      "Epoch: 27/30...  Loss: 1.6471\n",
      "Epoch: 27/30...  Loss: 1.6419\n",
      "Epoch: 27/30...  Loss: 1.6488\n",
      "Epoch: 27/30...  Loss: 1.6440\n",
      "Epoch: 27/30...  Loss: 1.6432\n",
      "Epoch: 27/30...  Loss: 1.6405\n",
      "Epoch: 27/30...  Loss: 1.6543\n",
      "Epoch: 27/30...  Loss: 1.6579\n",
      "Epoch: 27/30...  Loss: 1.6388\n",
      "Epoch: 27/30...  Loss: 1.6458\n",
      "Epoch: 27/30...  Loss: 1.6452\n",
      "Epoch: 27/30...  Loss: 1.6423\n",
      "Epoch: 27/30...  Loss: 1.6557\n",
      "Epoch: 27/30...  Loss: 1.6415\n",
      "Epoch: 27/30...  Loss: 1.6515\n",
      "Epoch: 27/30...  Loss: 1.6538\n",
      "Epoch: 27/30...  Loss: 1.6449\n",
      "Epoch: 27/30...  Loss: 1.6387\n",
      "Epoch: 27/30...  Loss: 1.6488\n",
      "Epoch: 27/30...  Loss: 1.6527\n",
      "Epoch: 27/30...  Loss: 1.6523\n",
      "Epoch: 27/30...  Loss: 1.6641\n",
      "Epoch: 27/30...  Loss: 1.6463\n",
      "Epoch: 28/30...  Loss: 1.3937\n",
      "Epoch: 28/30...  Loss: 1.6371\n",
      "Epoch: 28/30...  Loss: 1.6459\n",
      "Epoch: 28/30...  Loss: 1.6543\n",
      "Epoch: 28/30...  Loss: 1.6407\n",
      "Epoch: 28/30...  Loss: 1.6475\n",
      "Epoch: 28/30...  Loss: 1.6482\n",
      "Epoch: 28/30...  Loss: 1.6479\n",
      "Epoch: 28/30...  Loss: 1.6417\n",
      "Epoch: 28/30...  Loss: 1.6653\n",
      "Epoch: 28/30...  Loss: 1.6382\n",
      "Epoch: 28/30...  Loss: 1.6459\n",
      "Epoch: 28/30...  Loss: 1.6466\n",
      "Epoch: 28/30...  Loss: 1.6461\n",
      "Epoch: 28/30...  Loss: 1.6506\n",
      "Epoch: 28/30...  Loss: 1.6389\n",
      "Epoch: 28/30...  Loss: 1.6369\n",
      "Epoch: 28/30...  Loss: 1.6429\n",
      "Epoch: 28/30...  Loss: 1.6560\n",
      "Epoch: 28/30...  Loss: 1.6436\n",
      "Epoch: 28/30...  Loss: 1.6564\n",
      "Epoch: 28/30...  Loss: 1.6597\n",
      "Epoch: 28/30...  Loss: 1.6437\n",
      "Epoch: 29/30...  Loss: 0.6568\n",
      "Epoch: 29/30...  Loss: 1.6376\n",
      "Epoch: 29/30...  Loss: 1.6391\n",
      "Epoch: 29/30...  Loss: 1.6520\n",
      "Epoch: 29/30...  Loss: 1.6422\n",
      "Epoch: 29/30...  Loss: 1.6407\n",
      "Epoch: 29/30...  Loss: 1.6618\n",
      "Epoch: 29/30...  Loss: 1.6510\n",
      "Epoch: 29/30...  Loss: 1.6383\n",
      "Epoch: 29/30...  Loss: 1.6517\n",
      "Epoch: 29/30...  Loss: 1.6535\n",
      "Epoch: 29/30...  Loss: 1.6425\n",
      "Epoch: 29/30...  Loss: 1.6494\n",
      "Epoch: 29/30...  Loss: 1.6327\n",
      "Epoch: 29/30...  Loss: 1.6511\n",
      "Epoch: 29/30...  Loss: 1.6593\n",
      "Epoch: 29/30...  Loss: 1.6302\n",
      "Epoch: 29/30...  Loss: 1.6496\n",
      "Epoch: 29/30...  Loss: 1.6396\n",
      "Epoch: 29/30...  Loss: 1.6400\n",
      "Epoch: 29/30...  Loss: 1.6542\n",
      "Epoch: 29/30...  Loss: 1.6379\n",
      "Epoch: 29/30...  Loss: 1.6517\n",
      "Epoch: 29/30...  Loss: 1.6523\n",
      "Epoch: 30/30...  Loss: 1.5649\n",
      "Epoch: 30/30...  Loss: 1.6529\n",
      "Epoch: 30/30...  Loss: 1.6504\n",
      "Epoch: 30/30...  Loss: 1.6573\n",
      "Epoch: 30/30...  Loss: 1.6439\n",
      "Epoch: 30/30...  Loss: 1.6450\n",
      "Epoch: 30/30...  Loss: 1.6436\n",
      "Epoch: 30/30...  Loss: 1.6403\n",
      "Epoch: 30/30...  Loss: 1.6425\n",
      "Epoch: 30/30...  Loss: 1.6528\n",
      "Epoch: 30/30...  Loss: 1.6442\n",
      "Epoch: 30/30...  Loss: 1.6524\n",
      "Epoch: 30/30...  Loss: 1.6453\n",
      "Epoch: 30/30...  Loss: 1.6423\n",
      "Epoch: 30/30...  Loss: 1.6515\n",
      "Epoch: 30/30...  Loss: 1.6353\n",
      "Epoch: 30/30...  Loss: 1.6499\n",
      "Epoch: 30/30...  Loss: 1.6505\n",
      "Epoch: 30/30...  Loss: 1.6473\n",
      "Epoch: 30/30...  Loss: 1.6440\n",
      "Epoch: 30/30...  Loss: 1.6378\n",
      "Epoch: 30/30...  Loss: 1.6346\n",
      "Epoch: 30/30...  Loss: 1.6318\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "epochs = 30\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() \n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAGZCAYAAAC+BGE/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkCgZOkiRJklThfwE7brrs1I5ZhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x234ab044400>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 204,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test out your network!\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "ps = F.softmax(logits, dim=1)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your network is trained, you'll want to save it to disk so you can load it later instead of training it again. Obviously, it's impractical to train a network every time you need one. In practice, you'll train it once, save the model, then reload it for further training or making predictions. In the next part, I'll show you how to save and load trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
